# PART 1

Goal: the objective of this project is to analyze how the memory hierarchy (specifically L1 Data and Instruction caches) affects the performance of a processor. We are running the code to measure execution time and cache miss rates.

Code: The code implements a "stencil" operation, whis is common in image processing algorithms. It works with two 16 x 16 matrices, A and B:

    - Inicialization: First, it fills matrices A and B with generated values
    - Processing: Ir ireares through the inner elements of the matrices. For every position (i, j)

        - It calculates the Maximum value among the vertical neighbors in matrix A (A[i-1], A[i], A[i+1]) and stores it in a result matrix MAX
        - It calculates the Minimum value among the vertical neighbors in matrix B (b[i-1], B[i], B[i+1]) and stores it in a result matrix MIN 

In part 1 we use a very samll Direct Mapped Cache (256 bytes). Since the distance between out matrices (1024 bytes) is a multiple of the cache size, the data from matrix A, matrix B, ande the result matrices constantly map to the same cache blocks.

This causes extreme Cache Thrashing (conflict misses), resulting in a Data Cache Miss Rate of nearly 100%, which drastically slows down execution.

For the part 1 we use the code without loop enrolling



# MACHINE CONFIG

CORE 
-pipelined yes
-delay slot yes
-hazard unit stall or forward when hazard is detected yes

MEMORY
-read 10
-write 10

PROGRAM CACHE
-number of sets 16
-block size 2
-degree of associativity 1
-replacement policy random

DATA CACHE
-number of sets 32
-block size 2
-degree of associativity 1
-replacement policy random
-writeback policy write through - write allocate



# CODE

.text 0x00400000
.globl main

main:
    # --- Inicialización de N ---
    la   $t0, N             
    lw   $s0, 0($t0)        # Carga N en $s0. N = 16.

    # ============================================
    # INICIALIZACIÓN DE DATOS (Rellenar A y B)
    # ============================================
    la   $t1, A             # Carga dirección base de matriz A
    la   $t2, B             # Carga dirección base de matriz B
    mul  $t3, $s0, $s0      # Calcula N * N = 256 (Total de elementos)
    li   $t4, 0             # Inicializa contador k = 0

init_loop:
    beq  $t4, $t3, start_proc # Si k == 256, termina la inicialización
    nop                       # Delay Slot (Slot de retardo para el salto)

    # Generar valores para A y B
    addi $t5, $t4, 5        # Genera valor para A: k + 5
    sw   $t5, 0($t1)        # Guarda el valor en A[k]

    sll  $t6, $t4, 1        # Genera valor para B: k * 2 (shift left 1 = mul por 2)
    sw   $t6, 0($t2)        # Guarda el valor en B[k]

    # Avanzar punteros y contador
    addi $t1, $t1, 4        # Avanza puntero de A a la siguiente palabra (4 bytes)
    addi $t2, $t2, 4        # Avanza puntero de B a la siguiente palabra
    addi $t4, $t4, 1        # Incrementa contador k
    
    j    init_loop          # Salta al inicio del bucle de inicialización
    nop                     # Delay Slot

start_proc:
    li   $s1, 1             # Inicializa índice fila i = 1 (evita borde superior)

loop_i:
    # --- Condición del bucle externo (i) ---
    addi $t1, $s0, -1       # $t1 = N - 1 (Límite superior)
    slt  $t0, $s1, $t1      # Comprueba si i < N-1. Si es cierto, $t0 = 1
    beq  $t0, $zero, end    # Si $t0 es 0 (i >= N-1), termina el programa
    nop                     # Delay Slot

    li   $s2, 1             # Inicializa índice columna j = 1 (evita borde izquierdo)

loop_j:
    # --- Condición del bucle interno (j) ---
    slt  $t0, $s2, $t1      # Comprueba si j < N-1
    beq  $t0, $zero, next_i # Si j >= N-1, termina bucle interno y va a next_i
    nop                     # Delay Slot

    # --- Cálculo del Offset Base [i][j] ---
    # Offset = (i * 16 * 4) + (j * 4)
    sll  $t2, $s1, 6        # $t2 = i * 64 bytes (salto de filas de 16 enteros)
    sll  $t3, $s2, 2        # $t3 = j * 4 bytes (salto de columnas)
    add  $t4, $t2, $t3      # $t4 = Offset total desde el inicio del array

    # ============================================
    # CÁLCULO DE MAX sobre A[i-1][j], A[i][j], A[i+1][j]
    # ============================================

    # --- Cargar A[i-1][j] ---
    la   $t5, A             # Carga dirección base de A
    add  $t6, $t5, $t4      # $t6 apunta a la dirección de A[i][j]
    lw   $a0, -64($t6)      # Carga A[i-1][j] (Retrocede una fila: -64 bytes)

    # --- Cargar A[i][j] ---
    lw   $a1, 0($t6)        # Carga A[i][j] (Posición actual)

    # --- Cargar A[i+1][j] ---
    lw   $a2, 64($t6)       # Carga A[i+1][j] (Avanza una fila: +64 bytes)

    # --- Calcular MAX(a0, a1, a2) ---
    add  $t7, $a0, $zero    # Inicializa MAX temporal con el valor de A[i-1][j]

    # Comparar con A[i][j]
    slt  $t8, $t7, $a1      # Compara: ¿Es MAX < A[i][j]?
    beq  $t8, $zero, check_max2 # Si no es menor, salta a la siguiente comprobación
    nop                     # Delay Slot
    add  $t7, $a1, $zero    # Actualiza MAX = A[i][j]

check_max2:
    # Comparar con A[i+1][j]
    slt  $t8, $t7, $a2      # Compara: ¿Es MAX < A[i+1][j]?
    beq  $t8, $zero, store_max # Si no es menor, salta a guardar
    nop                     # Delay Slot
    add  $t7, $a2, $zero    # Actualiza MAX = A[i+1][j]

store_max:
    # Guardar resultado en MAX[i][j]
    la   $t8, MAX           # Carga dirección base de matriz MAX
    add  $t8, $t8, $t4      # Calcula dirección destino MAX[i][j]
    sw   $t7, 0($t8)        # Escribe el valor máximo calculado en memoria

    # ============================================
    # CÁLCULO DE MIN sobre B[i-1][j], B[i][j], B[i+1][j]
    # ============================================

    # --- Cargar B[i-1][j] ---
    la   $t5, B             # Carga dirección base de B
    add  $t6, $t5, $t4      # $t6 apunta a la dirección de B[i][j]
    lw   $a0, -64($t6)      # Carga B[i-1][j]

    # --- Cargar B[i][j] ---
    lw   $a1, 0($t6)        # Carga B[i][j]

    # --- Cargar B[i+1][j] ---
    lw   $a2, 64($t6)       # Carga B[i+1][j]

    # --- Calcular MIN(a0, a1, a2) ---
    add  $t7, $a0, $zero    # Inicializa MIN temporal con B[i-1][j]

    # Comparar con B[i][j]
    slt  $t8, $a1, $t7      # Compara: ¿Es B[i][j] < MIN?
    beq  $t8, $zero, check_min2 # Si no es menor, salta
    nop                     # Delay Slot
    add  $t7, $a1, $zero    # Actualiza MIN = B[i][j]

check_min2:
    # Comparar con B[i+1][j]
    slt  $t8, $a2, $t7      # Compara: ¿Es B[i+1][j] < MIN?
    beq  $t8, $zero, store_min # Si no es menor, salta
    nop                     # Delay Slot
    add  $t7, $a2, $zero    # Actualiza MIN = B[i+1][j]

store_min:
    # Guardar resultado en MIN[i][j]
    la   $t8, MIN           # Carga dirección base de matriz MIN
    add  $t8, $t8, $t4      # Calcula dirección destino MIN[i][j]
    sw   $t7, 0($t8)        # Escribe el valor mínimo calculado en memoria

    # --- Control de Bucles ---
    j    loop_j             # Salta al inicio del bucle interno (siguiente j)
    addi $s2, $s2, 1        # Incrementa j (ejecutado en Delay Slot)

next_i:
    j    loop_i             # Salta al inicio del bucle externo (siguiente i)
    addi $s1, $s1, 1        # Incrementa i (ejecutado en Delay Slot)

end:
    # --- Finalización del Programa ---
    li   $v0, 10            # Código syscall para terminar ejecución (exit)
    syscall

# --- SECCIÓN DE DATOS ---
.data
N:      .word 16        # Tamaño de la matriz (16x16)
A:      .space 1024     # Espacio para Matriz A (256 palabras)
B:      .space 1024     # Espacio para Matriz B (256 palabras)
MAX:    .space 1024     # Espacio para matriz de salida MAX
MIN:    .space 1024     # Espacio para matriz de salida MIN



# SOLUTION

Total cycles: 12628
Stalls: 1010


PROGRAM CACHE
Hits: 9356
Misses: 3270
Hit Rate: 74.101%
Miss rate: 25.899%

The instruction cache performance is reasonable because the code consists of a small loop that repeats. Once the loop instructions are loaded into the cache, they are reused many times. The 3270 misses occur mainly when loading the initialization code and during the first few iterations.


DATA CACHE
Hits: 1
Misses: 2080
Hit Rate: 0.048%
Miss rate: 99.952%

The miss rate almost 100% due to the tiny size of the cache (256 bytes) compared to the size of the working data. Continuous "thrashing" occurs.

-------------------------

# PART 2

For part 2 we use the same code but with a different configuration to compare and optimize the changes


# MACHINE CONFIG

MACHINE CONFIG

CORE
-Pipelined: yes
-Delay slot: yes
-Hazard unit: stall or forward when hazard is detected

MEMORY
-Read: 10
-Write: 10

DATA CACHE (256 bytes):
- Number of sets: 4
- Block size: 4
- Degree of associativity: 4
- Replacement: LRU
- Writeback: write back

PROGRAM CACHE (128 bytes):
- Number of sets: 4 
- Block size: 4 
- Degree of associativity: 2
- Replacement: LRU

# SOLUTION

PROGRAM CACHE
                PARTE 1       PARTE 2       MEJORA
Hits:           9356          10223         +9.3%
Misses:         3270          2403          -26.5%
Hit Rate:       74.101%       80.968%       +6.867 puntos
Miss Rate:      25.899%       19.032%       -6.867 puntos

- Block size (4 words): Increasing the block size exploits spatial locality, pre-loading sequential instructions from the loop before they are needed

- Associativity (2 way): This reduced conflict misses, allowing the main loop instructions to stay in the cache longer without being evicted by other code


DATA CACHE
                PARTE 1       PARTE 2       MEJORA
Hits:           1             383           +38200%
Misses:         2080          1698          -18.4%
Hit Rate:       0.048%        18.405%       +18.357 puntos
Miss Rate:      99.952%       81.595%       -18.357 puntos

- Associativity (4-way): This was the critical factor. It allowed parts of matrices A, B, and the results to coexist in the cache simultaneously, mitigating the severe thrashing seen in Part 1.

- Block Size (4 words): This takes advantage of spatial locality. When one miss occurs, 4 neighbor elements are loaded, allowing subsequent accesses (j+1, j+2) to result in hits.


# EXPLAIN

For Instructions: We increased the Block Size. Since code is sequential, fetching more words at once pre-loaded the next instructions, reducing misses.

For Data: We increased Associativity to 4-way. In Part 1, the matrices were fighting for the same spot (thrashing). With 4 ways, we gave them 'more lanes' to coexist, which allowed the Block Size to actually work and save neighbors for later use.

-----------------

# PART 3

In this part we implemented loop unrolling to reduce the overhead of control instructions. This optimization minimizes pipeline stalls and maximizes instruction throughput, although it trades off a slight increase in instruction cache pressure due to larger static code size

# MACHINE CONFIG

PROGRAM CACHE
-number of sets 16
-block size 2
-degree of associativity 1
-replacement policy random

DATA CACHE
-number of sets 4
-block size 4
-degree of associativity 4
-replacement policy lru
-writeback policy write back


# CODE

.text 0x00400000
.globl main

main:
    # --- 1. Inicialización de Constantes y Punteros ---
    la   $t0, N             # Carga la dirección de la variable N en memoria
    lw   $s0, 0($t0)        # Carga el valor de N en $s0. N = 16.

    # ============================================
    # 2. INICIALIZACIÓN DE DATOS (Rellenar A y B)
    # ============================================
    la   $t1, A             # $t1 = Puntero base a la matriz A
    la   $t2, B             # $t2 = Puntero base a la matriz B
    mul  $t3, $s0, $s0      # $t3 = N * N = 256 (Total de elementos a inicializar)
    li   $t4, 0             # $t4 = Contador k = 0

init_loop:
    # Comprobación del bucle de inicialización
    beq  $t4, $t3, start_proc # Si k == 256, terminamos inicialización y vamos a procesar
    nop                       # Delay Slot (instrucción ejecutada tras el salto)

    # Generar y guardar valor para A[k]
    addi $t5, $t4, 5        # $t5 = k + 5
    sw   $t5, 0($t1)        # Guarda el valor en la dirección actual de A

    # Generar y guardar valor para B[k]
    sll  $t6, $t4, 1        # $t6 = k * 2 (desplazamiento de bits = multiplicar por 2)
    sw   $t6, 0($t2)        # Guarda el valor en la dirección actual de B

    # Avanzar punteros y contador
    addi $t1, $t1, 4        # Avanza puntero A a la siguiente palabra (4 bytes)
    addi $t2, $t2, 4        # Avanza puntero B a la siguiente palabra (4 bytes)
    addi $t4, $t4, 1        # Incrementa contador k
    j    init_loop          # Salta al inicio del bucle
    nop                     # Delay Slot

start_proc:
    # ============================================
    # 3. PROCESAMIENTO (LOOP UNROLLING FACTOR 2)
    # ============================================
    # Recorremos la matriz evitando bordes.
    # i va de 1 a N-2.
    # j va de 1 a N-2, pero avanza de 2 en 2 (1, 3, 5...)
    
    li   $s1, 1             # Inicializa índice de fila i = 1

loop_i:
    # --- Condición del bucle externo (Filas) ---
    addi $t1, $s0, -1       # $t1 = N - 1 (15)
    slt  $t0, $s1, $t1      # ¿Es i < 15?
    beq  $t0, $zero, end    # Si i >= 15, termina el programa
    nop                     # Delay Slot

    li   $s2, 1             # Inicializa índice de columna j = 1

loop_j:
    # --- Condición del bucle interno (Columnas) ---
    slt  $t0, $s2, $t1      # ¿Es j < 15?
    beq  $t0, $zero, next_i # Si j >= 15, termina fila y pasa a siguiente i
    nop                     # Delay Slot

    # -----------------------------------------------------------------
    # BLOQUE 1: PROCESAMIENTO DE LA COLUMNA ACTUAL [j]
    # -----------------------------------------------------------------
    
    # --- Paso 1: Calcular Offset Base para [i][j] ---
    sll  $t2, $s1, 6        # $t2 = i * 64 bytes (cada fila tiene 16 enteros * 4 bytes)
    sll  $t3, $s2, 2        # $t3 = j * 4 bytes
    add  $t4, $t2, $t3      # $t4 = Offset total de bytes para A[i][j]

    # --- Paso 2: Cargar vecinos verticales de A para [j] ---
    la   $t5, A             # Carga base de A
    add  $t6, $t5, $t4      # $t6 = Dirección memoria de A[i][j]
    lw   $a0, -64($t6)      # Carga A[i-1][j] (Fila anterior)
    lw   $a1, 0($t6)        # Carga A[i][j]   (Fila actual)
    lw   $a2, 64($t6)       # Carga A[i+1][j] (Fila siguiente)

    # --- Paso 3: Calcular MAX(a0, a1, a2) ---
    add  $t7, $a0, $zero    # Asumimos temporalmente que MAX es A[i-1][j]
    
    # Comparar con el segundo elemento
    slt  $t8, $t7, $a1      # ¿Es MAX actual < A[i][j]?
    beq  $t8, $zero, chk_mx2_1 # Si no, salta
    nop
    add  $t7, $a1, $zero    # Si sí, actualiza MAX = A[i][j]

chk_mx2_1:
    # Comparar con el tercer elemento
    slt  $t8, $t7, $a2      # ¿Es MAX actual < A[i+1][j]?
    beq  $t8, $zero, str_mx_1 # Si no, salta a guardar
    nop
    add  $t7, $a2, $zero    # Si sí, actualiza MAX = A[i+1][j]

str_mx_1:
    # Guardar resultado MAX en memoria
    la   $t8, MAX           # Carga base de matriz MAX
    add  $t8, $t8, $t4      # Suma offset actual
    sw   $t7, 0($t8)        # Guarda el máximo encontrado en MAX[i][j]

    # --- Paso 4: Cargar vecinos verticales de B para [j] ---
    la   $t5, B             # Carga base de B
    add  $t6, $t5, $t4      # $t6 = Dirección memoria de B[i][j]
    lw   $a0, -64($t6)      # Carga B[i-1][j]
    lw   $a1, 0($t6)        # Carga B[i][j]
    lw   $a2, 64($t6)       # Carga B[i+1][j]

    # --- Paso 5: Calcular MIN(a0, a1, a2) ---
    add  $t7, $a0, $zero    # Asumimos temporalmente que MIN es B[i-1][j]

    # Comparar con el segundo elemento
    slt  $t8, $a1, $t7      # ¿Es B[i][j] < MIN actual?
    beq  $t8, $zero, chk_mn2_1
    nop
    add  $t7, $a1, $zero    # Si sí, actualiza MIN = B[i][j]

chk_mn2_1:
    # Comparar con el tercer elemento
    slt  $t8, $a2, $t7      # ¿Es B[i+1][j] < MIN actual?
    beq  $t8, $zero, str_mn_1
    nop
    add  $t7, $a2, $zero    # Si sí, actualiza MIN = B[i+1][j]

str_mn_1:
    # Guardar resultado MIN en memoria
    la   $t8, MIN           # Carga base de matriz MIN
    add  $t8, $t8, $t4      # Suma offset actual
    sw   $t7, 0($t8)        # Guarda el mínimo encontrado en MIN[i][j]

    # -----------------------------------------------------------------
    # BLOQUE 2: PROCESAMIENTO DE LA SIGUIENTE COLUMNA [j+1] (UNROLLING)
    # -----------------------------------------------------------------
    # Aquí empieza la optimización. En lugar de volver al inicio del bucle,
    # procesamos el siguiente elemento inmediatamente.
    
    # Ajustamos el Offset: Solo necesitamos avanzar 4 bytes (1 palabra)
    addi $t4, $t4, 4        # Ahora $t4 apunta al offset de [i][j+1]

    # --- Paso 6: Cargar vecinos verticales de A para [j+1] ---
    la   $t5, A
    add  $t6, $t5, $t4      # Puntero a A[i][j+1]
    lw   $a0, -64($t6)      # A[i-1][j+1]
    lw   $a1, 0($t6)        # A[i][j+1]
    lw   $a2, 64($t6)       # A[i+1][j+1]

    # --- Paso 7: Calcular MAX para [j+1] ---
    add  $t7, $a0, $zero    # MAX temporal
    slt  $t8, $t7, $a1
    beq  $t8, $zero, chk_mx2_2
    nop
    add  $t7, $a1, $zero
chk_mx2_2:
    slt  $t8, $t7, $a2
    beq  $t8, $zero, str_mx_2
    nop
    add  $t7, $a2, $zero
str_mx_2:
    # Guardar en MAX[i][j+1]
    la   $t8, MAX
    add  $t8, $t8, $t4      # Usamos el offset actualizado
    sw   $t7, 0($t8)

    # --- Paso 8: Cargar vecinos verticales de B para [j+1] ---
    la   $t5, B
    add  $t6, $t5, $t4      # Puntero a B[i][j+1]
    lw   $a0, -64($t6)      # B[i-1][j+1]
    lw   $a1, 0($t6)        # B[i][j+1]
    lw   $a2, 64($t6)       # B[i+1][j+1]

    # --- Paso 9: Calcular MIN para [j+1] ---
    add  $t7, $a0, $zero    # MIN temporal
    slt  $t8, $a1, $t7
    beq  $t8, $zero, chk_mn2_2
    nop
    add  $t7, $a1, $zero
chk_mn2_2:
    slt  $t8, $a2, $t7
    beq  $t8, $zero, str_mn_2
    nop
    add  $t7, $a2, $zero
str_mn_2:
    # Guardar en MIN[i][j+1]
    la   $t8, MIN
    add  $t8, $t8, $t4      # Usamos el offset actualizado
    sw   $t7, 0($t8)

    # --- ACTUALIZACIÓN DE BUCLES ---
    # Importante: Como hemos procesado j y j+1, incrementamos el contador en 2
    addi $s2, $s2, 2        # j = j + 2
    j    loop_j             # Volver a comprobar condición de bucle j
    nop                     # Delay Slot

next_i:
    addi $s1, $s1, 1        # i = i + 1 (Siguiente fila)
    j    loop_i             # Volver a comprobar condición de bucle i
    nop                     # Delay Slot

end:
    li   $v0, 10            # Código syscall para salir
    syscall

# --- SECCIÓN DE DATOS ---
.data
N:      .word 16            # Tamaño matriz 16x16
A:      .space 1024         # Espacio para Matriz A
B:      .space 1024         # Espacio para Matriz B
MAX:    .space 1024         # Resultado MAX
MIN:    .space 1024         # Resultado MIN


# SOLUTION

DATA CACHE
            PARTE 1     PARTE 3     MEJORA
Hits        1           383         +38200%
Misses      2080        1698        -18.4%
Hit Rate    0.048%      18.405%     +18.357 puntos
Miss Rate   99.952%     81.595%     -18.357 puntos


PROGRAM CACHE
            PARTE 1     PARTE 3     MEJORA
Hits        9356        7568        -19.1%
Misses      3270        4386        +34.1%
Hit Rate    74.101%     63.309%     -10.792 puntos
Miss Rate   25.899%     36.691%     +10.792 puntos



# Extra Question Can you think of any modification to the program to improve the data cache miss rate? Note: You can modify either the data section or the code section of the program.

Add empty space (Padding) between the matrix declaration in the .data section to misalingn them. For example, declare a dummy variable (.space 16) between matrix A and B. This ensures that matrix B starts in a different cache set than matrix A, drastically reducing collisions (conflict misses) and lowering the Miss Rate. 